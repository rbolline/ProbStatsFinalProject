{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ce50e3-9328-498f-ad13-ae2a4f81eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from ghcn import load_daily\n",
    "from glob import glob\n",
    "import scipy.stats as stats\n",
    "\n",
    "from statsmodels.stats.descriptivestats import sign_test\n",
    "# Data files\n",
    "files = sorted(glob('ghcnd_small/*.dly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386cb41a-7ffb-4399-9170-626b7f9589f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data about stations (we only the station ID and latitude)\n",
    "# that are in the northern hemisphere (a.k.a. latitude > 0)\n",
    "north_stations = pd.read_fwf(\"ghcnd-stations.txt\", header=None, usecols=[0, 1])\n",
    "north_stations.columns = [\"station_id\", \"latitude\"]\n",
    "north_stations = north_stations[north_stations[\"latitude\"] > 0]\n",
    "north_stations.set_index(\"station_id\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d18b8f7e-f444-4cab-ad5f-0a0fe4927b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:22<00:00, 12.14it/s]\n"
     ]
    }
   ],
   "source": [
    "data_all_t = []\n",
    "for filename in tqdm.tqdm(files):\n",
    "    # Get the station name from the filename\n",
    "    station_name = filename.split(sep='/')[-1][:-4]\n",
    "    # Get the latitude of the station if it's in the dictionary (if not, it's -1)\n",
    "    try:\n",
    "        latitude = north_stations['latitude'][station_name]\n",
    "    except:\n",
    "        latitude = -1\n",
    "    # Only load this file if the station is in the northern hemisphere (a.k.a. having latitude > 0)\n",
    "    if latitude < 0:\n",
    "        continue\n",
    "    \n",
    "    # All the data for one station\n",
    "    df_temp = pd.DataFrame.from_records(load_daily(filename))\n",
    "\n",
    "    # Extract the temperature data\n",
    "    filter_ = np.logical_or(df_temp[\"element\"] == \"TMIN\", df_temp[\"element\"] == \"TMAX\")\n",
    "    \n",
    "    temperatures = df_temp[filter_]\n",
    "\n",
    "    # Delete unnecessary columns\n",
    "    temperatures = temperatures.drop(columns=[\"measurement\", \"quality\", \"source\"])\n",
    "\n",
    "    data_all_t.append(temperatures)\n",
    "\n",
    "    del filename, station_name, latitude, df_temp, filter_, temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac5f6a4-babf-4235-94ea-044dad78844f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>element</th>\n",
       "      <th>day</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGM00060490</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGM00060490</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGM00060490</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>3</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGM00060490</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGM00060490</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50821</th>\n",
       "      <td>VMM00048808</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>13</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50822</th>\n",
       "      <td>VMM00048808</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>14</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50823</th>\n",
       "      <td>VMM00048808</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>15</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50824</th>\n",
       "      <td>VMM00048808</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>16</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50825</th>\n",
       "      <td>VMM00048808</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>17</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7322806 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id  year  month element  day  value\n",
       "0      AGM00060490  1957      1    TMAX    1    178\n",
       "1      AGM00060490  1957      1    TMAX    2    150\n",
       "2      AGM00060490  1957      1    TMAX    3    161\n",
       "3      AGM00060490  1957      1    TMAX    4    172\n",
       "4      AGM00060490  1957      1    TMAX    5    172\n",
       "...            ...   ...    ...     ...  ...    ...\n",
       "50821  VMM00048808  2021      3    TMIN   13    195\n",
       "50822  VMM00048808  2021      3    TMIN   14    196\n",
       "50823  VMM00048808  2021      3    TMIN   15    211\n",
       "50824  VMM00048808  2021      3    TMIN   16    212\n",
       "50825  VMM00048808  2021      3    TMIN   17    214\n",
       "\n",
       "[7322806 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_t = pd.concat(data_all_t)\n",
    "\n",
    "# Delete missing data\n",
    "df_t = data_all_t[data_all_t[\"value\"] != -9999]\n",
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83bd0b57-d9f8-425d-a23f-f4a20b82957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11486, 1)\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# Compute each station's annual mean temperature\n",
    "# ===========================================================\n",
    "\n",
    "# For each station and for each day, compute the midpoint temperature by\n",
    "# averaging the min and max temperatures\n",
    "mid_temps = df_t.where(np.logical_or(df_t[\"element\"] == \"TMIN\",\n",
    "                            df_t[\"element\"] == \"TMAX\")).groupby(by=[\"station_id\", \"year\", \"month\", \"day\"]).mean().reset_index()\n",
    "\n",
    "# For each station and for each year, compute the average temperature across that year\n",
    "temps = mid_temps.groupby(by=[\"station_id\", \"year\"]).mean()[\"value\"].reset_index()\n",
    "\n",
    "# All temperatures are in tenths of degree Celsius, so divide by 10 to get\n",
    "# actual Celsius temperatures\n",
    "temps[\"value\"] /= 10\n",
    "\n",
    "# Convert year to int type\n",
    "temps[\"year\"] = temps[\"year\"].astype(int)\n",
    "\n",
    "temps = temps.set_index([\"station_id\", \"year\"])\n",
    "temps.rename(columns={\"value\": \"temp\"}, inplace=True)\n",
    "print(temps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f77e21-8aee-4ad5-a144-d174616426fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AGM00060490</th>\n",
       "      <th>1957</th>\n",
       "      <td>17.622492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>18.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>18.911058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>19.716121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>20.243947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">VMM00048808</th>\n",
       "      <th>2017</th>\n",
       "      <td>20.512021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>21.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>23.860252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>20.951423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>16.163077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11486 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       temp\n",
       "station_id  year           \n",
       "AGM00060490 1957  17.622492\n",
       "            1958  18.110000\n",
       "            1959  18.911058\n",
       "            1960  19.716121\n",
       "            1961  20.243947\n",
       "...                     ...\n",
       "VMM00048808 2017  20.512021\n",
       "            2018  21.082609\n",
       "            2019  23.860252\n",
       "            2020  20.951423\n",
       "            2021  16.163077\n",
       "\n",
       "[11486 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fff561b-2b96-4e82-9a72-98db2a8f7173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:26<00:00, 11.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files... DONE\n"
     ]
    }
   ],
   "source": [
    "# We only care about stations in the northern hemisphere (latitude > 0)\n",
    "# So go through the list of files, and only load files corresponding to\n",
    "# stations in the northern hemisphere.\n",
    "data_all = []\n",
    "for filename in tqdm.tqdm(files):\n",
    "    # Get the station name from the filename\n",
    "    station_name = filename.split(sep='/')[-1][:-4]\n",
    "    # Get the latitude of the station if it's in the dictionary (if not, it's -1)\n",
    "    try:\n",
    "        latitude = north_stations['latitude'][station_name]\n",
    "    except:\n",
    "        latitude = -1\n",
    "    # Only load this file if the station is in the northern hemisphere (a.k.a. having latitude > 0)\n",
    "    if latitude < 0:\n",
    "        continue\n",
    "    \n",
    "    # All the data for one station\n",
    "    df = pd.DataFrame.from_records(load_daily(filename))\n",
    "\n",
    "    # Extract the temperature data\n",
    "    filter_ = np.logical_and(np.logical_and(np.logical_and(np.logical_and(\n",
    "                                        df[\"element\"] != \"TMIN\",\n",
    "                                        df[\"element\"] != \"TMAX\"), \n",
    "                                        df[\"element\"] != \"PRCP\"), \n",
    "                                        df[\"element\"] != \"SNOW\"),\n",
    "                                        df[\"element\"] != \"TAVG\")\n",
    "    \n",
    "    temperatures = df[filter_]\n",
    "\n",
    "    # Delete unnecessary columns\n",
    "    temperatures = temperatures.drop(columns=[\"measurement\", \"quality\", \"source\"])\n",
    "\n",
    "    data_all.append(temperatures)\n",
    "\n",
    "    del filename, station_name, latitude, df, filter_, temperatures\n",
    "print(\"Reading files... DONE\")\n",
    "\n",
    "# Combine all the dataframes\n",
    "data_all = pd.concat(data_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d892ef1-8c58-44e7-8c5d-92fffdcb90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_data = data_all[data_all.value != -9999].dropna()\n",
    "df = nn_data[nn_data.element != 'SNWD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94e82164-573e-4e8c-b54b-21e0091dcc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>element</th>\n",
       "      <th>day</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>ASN00001031</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>DAPR</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>ASN00001031</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>DWPR</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>ASN00001031</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>MDPR</td>\n",
       "      <td>31</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>ASN00001031</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>DAPR</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>ASN00001031</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>DWPR</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95554</th>\n",
       "      <td>USW00094724</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>WSF5</td>\n",
       "      <td>13</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95555</th>\n",
       "      <td>USW00094724</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>WSF5</td>\n",
       "      <td>14</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95556</th>\n",
       "      <td>USW00094724</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>WSF5</td>\n",
       "      <td>15</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95557</th>\n",
       "      <td>USW00094724</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>WSF5</td>\n",
       "      <td>16</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95558</th>\n",
       "      <td>USW00094724</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>WSF5</td>\n",
       "      <td>17</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2474052 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id  year  month element  day  value\n",
       "774    ASN00001031  1998     10    DAPR   31     16\n",
       "805    ASN00001031  1998     10    DWPR   31      5\n",
       "836    ASN00001031  1998     10    MDPR   31    770\n",
       "897    ASN00001031  1998     11    DAPR   30      4\n",
       "928    ASN00001031  1998     11    DWPR   30      4\n",
       "...            ...   ...    ...     ...  ...    ...\n",
       "95554  USW00094724  2021      3    WSF5   13    188\n",
       "95555  USW00094724  2021      3    WSF5   14    183\n",
       "95556  USW00094724  2021      3    WSF5   15    188\n",
       "95557  USW00094724  2021      3    WSF5   16     85\n",
       "95558  USW00094724  2021      3    WSF5   17     81\n",
       "\n",
       "[2474052 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240831d-4133-4343-a6c0-3a5bb301d48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af2f56b6-6c37-4553-91d4-cbc73f9e17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_yearly_metrics(metrics):\n",
    "    metrics_data = []\n",
    "    for metric in tqdm.tqdm(metrics):\n",
    "        # Extract the data\n",
    "        data = df.where(df['element'] == metric).dropna()\n",
    "        \n",
    "        # Delete missing data, and unnecessary columns\n",
    "        data = data[data[\"value\"] != -9999]\n",
    "\n",
    "        # For each station and for each year, compute the average metric across that year\n",
    "        result = data.groupby(by=[\"station_id\", \"year\"]).mean()[\"value\"].reset_index()\n",
    "\n",
    "        # Convert year to int type\n",
    "        result[\"year\"] = result[\"year\"].astype(int)\n",
    "        \n",
    "        result = result.set_index([\"station_id\", \"year\"])\n",
    "        result.rename(columns={\"value\": metric}, inplace=True)\n",
    "        \n",
    "        metrics_data.append(result)\n",
    "\n",
    "    return metrics_data\n",
    "\n",
    "# Join the temperature and metric data (on the index a.k.a. the year column)\n",
    "metrics_list = df['element'].unique()\n",
    "\n",
    "# data = pd.concat(data, axis=1, join=\"inner\", ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5b08cd8-7663-489f-876d-19f073bc6d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [01:12<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11486, 1), (3434, 1), (1282, 1), (3825, 1), (12, 1), (12, 1), (12, 1), (12, 1), (250, 1), (106, 1), (117, 1), (1052, 1), (776, 1), (1904, 1), (491, 1), (494, 1), (403, 1), (1141, 1), (378, 1), (2086, 1), (911, 1), (1342, 1), (190, 1), (4143, 1), (1007, 1), (184, 1), (256, 1), (241, 1), (107, 1), (107, 1), (52, 1), (52, 1), (350, 1), (109, 1), (11, 1), (100, 1), (101, 1), (43, 1), (43, 1), (61, 1), (61, 1), (9, 1), (9, 1), (10, 1), (10, 1), (145, 1), (13, 1), (185, 1), (71, 1), (132, 1), (131, 1), (132, 1), (131, 1), (41, 1), (2, 1), (44, 1), (35, 1), (1, 1), (1, 1), (36, 1), (37, 1), (7, 1), (6, 1), (6, 1), (33, 1), (47, 1), (17, 1), (6, 1), (36, 1), (4, 1), (6, 1), (28, 1), (28, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = [temps] + compute_yearly_metrics(metrics_list)\n",
    "print([x.shape for x in data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a218e3e0-3b69-46ed-8986-5044420785fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_data = [x if x.shape[0] > 400 else _ for x in data]\n",
    "data_df = pd.concat(data, axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35933d8d-ba1e-4628-b95a-8a89b33b9a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>DAPR</th>\n",
       "      <th>DWPR</th>\n",
       "      <th>MDPR</th>\n",
       "      <th>DATN</th>\n",
       "      <th>MDTN</th>\n",
       "      <th>DATX</th>\n",
       "      <th>MDTX</th>\n",
       "      <th>MDSF</th>\n",
       "      <th>WDFG</th>\n",
       "      <th>...</th>\n",
       "      <th>WSFM</th>\n",
       "      <th>WT15</th>\n",
       "      <th>WT17</th>\n",
       "      <th>WT21</th>\n",
       "      <th>WV20</th>\n",
       "      <th>WT22</th>\n",
       "      <th>WV01</th>\n",
       "      <th>WV03</th>\n",
       "      <th>WDF1</th>\n",
       "      <th>WSF1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AGM00060490</th>\n",
       "      <th>1957</th>\n",
       "      <td>17.622492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>18.110000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>18.911058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>19.716121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>20.243947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">VMM00048808</th>\n",
       "      <th>2017</th>\n",
       "      <td>20.512021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>21.082609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>23.860252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>20.951423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>16.163077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15601 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       temp  DAPR  DWPR  MDPR  DATN  MDTN  DATX  MDTX  MDSF  \\\n",
       "station_id  year                                                              \n",
       "AGM00060490 1957  17.622492   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            1958  18.110000   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            1959  18.911058   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            1960  19.716121   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            1961  20.243947   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "...                     ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "VMM00048808 2017  20.512021   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            2018  21.082609   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            2019  23.860252   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            2020  20.951423   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            2021  16.163077   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "                  WDFG  ...  WSFM  WT15  WT17  WT21  WV20  WT22  WV01  WV03  \\\n",
       "station_id  year        ...                                                   \n",
       "AGM00060490 1957   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            1958   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            1959   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            1960   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            1961   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "...                ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "VMM00048808 2017   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            2018   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            2019   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            2020   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "            2021   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "                  WDF1  WSF1  \n",
       "station_id  year              \n",
       "AGM00060490 1957   NaN   NaN  \n",
       "            1958   NaN   NaN  \n",
       "            1959   NaN   NaN  \n",
       "            1960   NaN   NaN  \n",
       "            1961   NaN   NaN  \n",
       "...                ...   ...  \n",
       "VMM00048808 2017   NaN   NaN  \n",
       "            2018   NaN   NaN  \n",
       "            2019   NaN   NaN  \n",
       "            2020   NaN   NaN  \n",
       "            2021   NaN   NaN  \n",
       "\n",
       "[15601 rows x 73 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50688fb8-cf6c-493e-a391-0733567a9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Once all the data for each station and year is calculated, \n",
    "build a factor vs temp list for all factors and make a sliding \n",
    "window of adjacent values per year.\n",
    "'''\n",
    "\n",
    "\n",
    "factor_df_list = []\n",
    "for col in data_df.columns:\n",
    "    if col == 'temp':\n",
    "        continue\n",
    "    factor_df_list.append(data_df[['temp', col]])\n",
    "        \n",
    "factor_df_list_adj = []\n",
    "for df_ in factor_df_list:\n",
    "    tr_df = df_.dropna().reset_index(level=\"year\")\n",
    "    year_column = tr_df[\"year\"]\n",
    "    all_years = year_column.unique()\n",
    "    all_years.sort()\n",
    "    if len(all_years) <= 2:\n",
    "        continue\n",
    "    all_adj_years = np.lib.stride_tricks.sliding_window_view(all_years, 2)\n",
    "    factor_df_list_adj.append((tr_df, all_adj_years)) if df_.dropna().shape[0] > 100 else _\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97330a29-3163-4519-9bbe-e1be02935d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# factor_df_list_adj[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68225369-eabe-4b92-b8aa-deb21b9f8f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:00<00:00, 191.02it/s]\n",
      "100%|██████████| 105/105 [00:00<00:00, 192.44it/s]\n",
      "100%|██████████| 73/73 [00:00<00:00, 197.45it/s]\n",
      "100%|██████████| 52/52 [00:00<00:00, 202.26it/s]\n",
      "100%|██████████| 52/52 [00:00<00:00, 218.03it/s]\n",
      "100%|██████████| 57/57 [00:00<00:00, 175.41it/s]\n",
      "100%|██████████| 125/125 [00:00<00:00, 165.34it/s]\n",
      "100%|██████████| 118/118 [00:00<00:00, 198.51it/s]\n",
      "100%|██████████| 113/113 [00:00<00:00, 212.96it/s]\n",
      "100%|██████████| 110/110 [00:00<00:00, 212.68it/s]\n",
      "100%|██████████| 126/126 [00:00<00:00, 205.55it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 211.13it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 168.86it/s]\n",
      "100%|██████████| 96/96 [00:00<00:00, 166.70it/s]\n",
      "100%|██████████| 126/126 [00:00<00:00, 180.99it/s]\n",
      "100%|██████████| 69/69 [00:00<00:00, 223.79it/s]\n",
      "100%|██████████| 124/124 [00:00<00:00, 158.46it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 186.56it/s]\n",
      "100%|██████████| 73/73 [00:00<00:00, 212.12it/s]\n",
      "100%|██████████| 82/82 [00:00<00:00, 230.54it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 235.49it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 208.63it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 191.34it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 182.97it/s]\n",
      "100%|██████████| 37/37 [00:00<00:00, 154.18it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 171.99it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 163.12it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 174.33it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 166.34it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 153.84it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "With a alpha of 0.05, calculate sign tests for each of the \n",
    "climate indicators for each pair of adjacent years. Calculate the proportion \n",
    "of years which were significant.\n",
    "'''\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "outputs = []\n",
    "for df_adj in factor_df_list_adj:\n",
    "    df_, all_adj_years = df_adj\n",
    "    num_sig_factor = 0\n",
    "    \n",
    "    for (year1, year2) in tqdm.tqdm(all_adj_years):\n",
    "        # Get station data for both years\n",
    "        data_year1 = df_[df_['year'] == year1]\n",
    "        data_year2 = df_[df_['year'] == year2]\n",
    "        \n",
    "        # Get specific columns\n",
    "        temp_year1 = data_year1[\"temp\"]\n",
    "        temp_year2 = data_year2[\"temp\"]\n",
    "        factor_year1 = data_year1[data_year1.columns[-1]]\n",
    "        factor_year2 = data_year2[data_year2.columns[-1]]\n",
    "\n",
    "        # Inner join on station id to find observations common between both years, and\n",
    "        # then compute the differences\n",
    "        temp_year_diff = pd.DataFrame(temp_year1).join(temp_year2, how=\"inner\",\n",
    "                                                         lsuffix=\"_{}\".format(year1),\n",
    "                                                         rsuffix=\"_{}\".format(year2)).diff(axis=1).iloc[:, 1]\n",
    "        factor_year_diff = pd.DataFrame(factor_year1).join(factor_year2, how=\"inner\",\n",
    "                                                         lsuffix=\"_{}\".format(year1),\n",
    "                                                         rsuffix=\"_{}\".format(year2)).diff(axis=1).iloc[:, 1]    \n",
    "        # Only looking at cases where there are at least 5 values. \n",
    "        # The sign test is able to handle a small number of values \n",
    "        # but we want to cap at 5 values minimum.\n",
    "        if factor_year_diff.shape[0] < 5 or temp_year_diff.shape[0] < 5:\n",
    "            continue\n",
    "        # Count the number of differences that are positive\n",
    "        #\n",
    "        # These three values will serve as our test statistics for a sign test on temperature,\n",
    "        # a sign test on precipitation, and a sign test on snowfall, respectively\n",
    "        test_stat_temp = np.count_nonzero(temp_year_diff > 0)\n",
    "        test_stat_factor = np.count_nonzero(factor_year_diff > 0)\n",
    "\n",
    "        # Convert each test statistic into a p-value using the binomial test. In this case, each\n",
    "        # test statistic is defined as the number of successes (a.k.a. the number of stations\n",
    "        # for which temperature increased, precipitation increased, and snowfall increased,\n",
    "        # respectively) out of all stations\n",
    "        p_value_temp = stats.binomtest(k=test_stat_temp, n=temp_year_diff.size, alternative='two-sided').pvalue\n",
    "        p_value_factor = stats.binomtest(k=test_stat_factor, n=factor_year_diff.size, alternative='two-sided').pvalue\n",
    "\n",
    "        # If the p-values for temperature and precipitation are BOTH significant, then it means\n",
    "        # that between year1 and year2, temperature and precipitation BOTH had a statistically\n",
    "        # significant increase\n",
    "        if p_value_temp < alpha and p_value_factor < alpha:\n",
    "            num_sig_factor += 1\n",
    "    outputs.append((df_.columns[-1], num_sig_factor/len(all_adj_years)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52365d60-c38c-48b9-b601-c30b4d4674fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WESD', 0.07017543859649122),\n",
       " ('WT01', 0.184),\n",
       " ('WT08', 0.00847457627118644),\n",
       " ('WT16', 0.008849557522123894),\n",
       " ('WT18', 0.00909090909090909),\n",
       " ('WT05', 0.015873015873015872),\n",
       " ('WT09', 0.02),\n",
       " ('WT03', 0.1640625),\n",
       " ('WT06', 0.09375),\n",
       " ('WT04', 0.03968253968253968),\n",
       " ('TOBS', 0.28225806451612906),\n",
       " ('WT11', 0.02702702702702703)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_outputs = []\n",
    "for op in outputs:\n",
    "    if op[1] != 0:\n",
    "        nonzero_outputs.append(op)\n",
    "nonzero_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dc74e0-1bff-482a-a96e-c5fc1da2a34f",
   "metadata": {},
   "source": [
    "#### Climate Indicator Significant proportions of adjacent years\n",
    " **WESD** (Water equivalent of snow on the ground) = 0.07017543859649122\n",
    " \n",
    " **WT01** (Fog, ice fog, or freezing fog (may include heavy fog)) = 0.184\n",
    " \n",
    " **WT08** (Smoke or haze) = 0.00847457627118644\n",
    " \n",
    " **WT16** (Rain) = 0.008849557522123894\n",
    " \n",
    " **WT18** (Snow, snow pellets, snow grains, or ice crystals) = 0.00909090909090909\n",
    " \n",
    " **WT05** (Hail) = 0.015873015873015872\n",
    " \n",
    " **WT09** (Blowing or drifting snow) = 0.02\n",
    " \n",
    " **WT03** (Thunder) = 0.1640625\n",
    " \n",
    " **WT06** (Glaze or rime) = 0.09375\n",
    " \n",
    " **WT04** (Ice pellets, sleet, snow pellets, or small hail) = 0.03968253968253968\n",
    " \n",
    " **TOBS** (Temperature at the time of observation) = 0.28225806451612906\n",
    " \n",
    " **WT11** (High or damaging winds) = 0.02702702702702703\n",
    " \n",
    "#### Analysis\n",
    " Our outputs here show a few different climate indicators and the respective significant proportions. These proportions show the fraction of yearly changes which had a significant change in temperature and in the respective indicator. We  ignore 'TOBS' as it refers to temperature at time of observation, which is a redundant indicator.\n",
    " \n",
    " For example, we look at 'WT01', which refers to Fog, ice fog, or freezing fog (may include heavy fog) climate patterns. Across all years, about 18% had significant increases in temperature and significant change in the weather pattern. This is valuable in telling us when increases in temperature affect the climate through different values. \n",
    " \n",
    " Another perspective would be that the increase in temperature and the increase in the climate indicators are not a causal effect, but have confounding variables in the mix which may be the cause for both. For example, WT03, Thunder, has a 16% significant factor. However we usually would not relate Thunder to increasing heat. Instead, there may be high humidity or hot weather near the respective stations which correlates with humid thunderstorms. \n",
    " \n",
    " What we find is that a majority of these indicators have confounding variables and are not directly related to temperature(i.e. Thunder or Fog). However, some indicators like WT04-6(Sleet/Ice Pellets, Hail, Glaze/Rime) are all very directly related to temperature. In general, higher temperatures equal less snow or ice. We cannot say the same for Thunder or WT08(Smoke or Haze)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "774f22be-5e2e-4fad-ad6e-ef4cbcd10ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>DWPR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ASN00015089</th>\n",
       "      <th>1976</th>\n",
       "      <td>25.184211</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>25.660606</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>30.145588</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ASN00018120</th>\n",
       "      <th>1983</th>\n",
       "      <td>16.493726</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>18.124344</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>17.732787</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>18.046027</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>17.490000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ASN00030024</th>\n",
       "      <th>1990</th>\n",
       "      <td>24.426374</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>24.401389</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ASN00040852</th>\n",
       "      <th>1993</th>\n",
       "      <td>18.451567</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>19.763793</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>18.460792</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>18.382877</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>29.583871</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ASN00086097</th>\n",
       "      <th>1965</th>\n",
       "      <td>14.190500</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>14.193750</td>\n",
       "      <td>2.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>14.299705</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>14.230249</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>14.169452</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ASN00091007</th>\n",
       "      <th>1971</th>\n",
       "      <td>13.268508</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>13.195219</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>12.956849</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>12.962842</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>12.652358</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ASN00091250</th>\n",
       "      <th>1986</th>\n",
       "      <td>14.002381</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>10.918293</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>12.287273</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ASN00096003</th>\n",
       "      <th>1976</th>\n",
       "      <td>7.862295</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>7.668219</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       temp      DWPR\n",
       "station_id  year                     \n",
       "ASN00015089 1976  25.184211  3.000000\n",
       "            1978  25.660606  2.000000\n",
       "            1980  30.145588  2.666667\n",
       "ASN00018120 1983  16.493726  2.000000\n",
       "            1988  18.124344  2.333333\n",
       "            2004  17.732787  3.000000\n",
       "            2005  18.046027  2.000000\n",
       "            2006  17.490000  2.000000\n",
       "ASN00030024 1990  24.426374  2.000000\n",
       "            1999  24.401389  2.000000\n",
       "ASN00040852 1993  18.451567  2.750000\n",
       "            1994  19.763793  2.250000\n",
       "            1996  18.460792  2.000000\n",
       "            1997  18.382877  2.000000\n",
       "            1999  29.583871  2.000000\n",
       "ASN00086097 1965  14.190500  2.571429\n",
       "            1966  14.193750  2.409091\n",
       "            1967  14.299705  2.500000\n",
       "            1973  14.230249  2.000000\n",
       "            1976  14.169452  2.000000\n",
       "ASN00091007 1971  13.268508  1.666667\n",
       "            1972  13.195219  1.000000\n",
       "            1975  12.956849  2.000000\n",
       "            1976  12.962842  2.000000\n",
       "            1978  12.652358  2.000000\n",
       "ASN00091250 1986  14.002381  1.000000\n",
       "            1987  10.918293  1.000000\n",
       "            1988  12.287273  1.000000\n",
       "ASN00096003 1976   7.862295  2.000000\n",
       "            1985   7.668219  2.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dapr.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e7d84-c135-4845-9dea-dc1dd3610a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
