{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f9ce50e3-9328-498f-ad13-ae2a4f81eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from ghcn import load_daily\n",
    "from glob import glob\n",
    "import scipy.stats as stats\n",
    "\n",
    "from statsmodels.stats.descriptivestats import sign_test\n",
    "# Data files\n",
    "files = sorted(glob('ghcnd_small/*.dly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386cb41a-7ffb-4399-9170-626b7f9589f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data about stations (we only the station ID and latitude)\n",
    "# that are in the northern hemisphere (a.k.a. latitude > 0)\n",
    "north_stations = pd.read_fwf(\"ghcnd-stations.txt\", header=None, usecols=[0, 1])\n",
    "north_stations.columns = [\"station_id\", \"latitude\"]\n",
    "north_stations = north_stations[north_stations[\"latitude\"] > 0]\n",
    "north_stations.set_index(\"station_id\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d18b8f7e-f444-4cab-ad5f-0a0fe4927b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:19<00:00, 12.53it/s]\n"
     ]
    }
   ],
   "source": [
    "data_all_t = []\n",
    "for filename in tqdm.tqdm(files):\n",
    "    # Get the station name from the filename\n",
    "    station_name = filename.split(sep='/')[-1][:-4]\n",
    "    # Get the latitude of the station if it's in the dictionary (if not, it's -1)\n",
    "    try:\n",
    "        latitude = north_stations['latitude'][station_name]\n",
    "    except:\n",
    "        latitude = -1\n",
    "    # Only load this file if the station is in the northern hemisphere (a.k.a. having latitude > 0)\n",
    "    if latitude < 0:\n",
    "        continue\n",
    "    \n",
    "    # All the data for one station\n",
    "    df_temp = pd.DataFrame.from_records(load_daily(filename))\n",
    "\n",
    "    # Extract the temperature data\n",
    "    filter_ = np.logical_or(df_temp[\"element\"] == \"TMIN\", df_temp[\"element\"] == \"TMAX\")\n",
    "    \n",
    "    temperatures = df_temp[filter_]\n",
    "\n",
    "    # Delete unnecessary columns\n",
    "    temperatures = temperatures.drop(columns=[\"measurement\", \"quality\", \"source\"])\n",
    "\n",
    "    data_all_t.append(temperatures)\n",
    "\n",
    "    del filename, station_name, latitude, df_temp, filter_, temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eac5f6a4-babf-4235-94ea-044dad78844f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>element</th>\n",
       "      <th>day</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGM00060490</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGM00060490</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGM00060490</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>3</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGM00060490</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGM00060490</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50821</th>\n",
       "      <td>VMM00048808</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>13</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50822</th>\n",
       "      <td>VMM00048808</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>14</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50823</th>\n",
       "      <td>VMM00048808</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>15</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50824</th>\n",
       "      <td>VMM00048808</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>16</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50825</th>\n",
       "      <td>VMM00048808</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>17</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7322806 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id  year  month element  day  value\n",
       "0      AGM00060490  1957      1    TMAX    1    178\n",
       "1      AGM00060490  1957      1    TMAX    2    150\n",
       "2      AGM00060490  1957      1    TMAX    3    161\n",
       "3      AGM00060490  1957      1    TMAX    4    172\n",
       "4      AGM00060490  1957      1    TMAX    5    172\n",
       "...            ...   ...    ...     ...  ...    ...\n",
       "50821  VMM00048808  2021      3    TMIN   13    195\n",
       "50822  VMM00048808  2021      3    TMIN   14    196\n",
       "50823  VMM00048808  2021      3    TMIN   15    211\n",
       "50824  VMM00048808  2021      3    TMIN   16    212\n",
       "50825  VMM00048808  2021      3    TMIN   17    214\n",
       "\n",
       "[7322806 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_t = pd.concat(data_all_t)\n",
    "\n",
    "# Delete missing data\n",
    "df_t = data_all_t[data_all_t[\"value\"] != -9999]\n",
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83bd0b57-d9f8-425d-a23f-f4a20b82957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11486, 1)\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# Compute each station's annual mean temperature\n",
    "# ===========================================================\n",
    "\n",
    "# For each station and for each day, compute the midpoint temperature by\n",
    "# averaging the min and max temperatures\n",
    "mid_temps = df_t.where(np.logical_or(df_t[\"element\"] == \"TMIN\",\n",
    "                            df_t[\"element\"] == \"TMAX\")).groupby(by=[\"station_id\", \"year\", \"month\", \"day\"]).mean().reset_index()\n",
    "\n",
    "# For each station and for each year, compute the average temperature across that year\n",
    "temps = mid_temps.groupby(by=[\"station_id\", \"year\"]).mean()[\"value\"].reset_index()\n",
    "\n",
    "# All temperatures are in tenths of degree Celsius, so divide by 10 to get\n",
    "# actual Celsius temperatures\n",
    "temps[\"value\"] /= 10\n",
    "\n",
    "# Convert year to int type\n",
    "temps[\"year\"] = temps[\"year\"].astype(int)\n",
    "\n",
    "temps = temps.set_index([\"station_id\", \"year\"])\n",
    "temps.rename(columns={\"value\": \"temp\"}, inplace=True)\n",
    "print(temps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27f77e21-8aee-4ad5-a144-d174616426fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AGM00060490</th>\n",
       "      <th>1957</th>\n",
       "      <td>17.622492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>18.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>18.911058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>19.716121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>20.243947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">VMM00048808</th>\n",
       "      <th>2017</th>\n",
       "      <td>20.512021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>21.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>23.860252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>20.951423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>16.163077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11486 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       temp\n",
       "station_id  year           \n",
       "AGM00060490 1957  17.622492\n",
       "            1958  18.110000\n",
       "            1959  18.911058\n",
       "            1960  19.716121\n",
       "            1961  20.243947\n",
       "...                     ...\n",
       "VMM00048808 2017  20.512021\n",
       "            2018  21.082609\n",
       "            2019  23.860252\n",
       "            2020  20.951423\n",
       "            2021  16.163077\n",
       "\n",
       "[11486 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fff561b-2b96-4e82-9a72-98db2a8f7173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:25<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files... DONE\n"
     ]
    }
   ],
   "source": [
    "# We only care about stations in the northern hemisphere (latitude > 0)\n",
    "# So go through the list of files, and only load files corresponding to\n",
    "# stations in the northern hemisphere.\n",
    "data_all = []\n",
    "for filename in tqdm.tqdm(files):\n",
    "    # Get the station name from the filename\n",
    "    station_name = filename.split(sep='/')[-1][:-4]\n",
    "    # Get the latitude of the station if it's in the dictionary (if not, it's -1)\n",
    "    try:\n",
    "        latitude = north_stations['latitude'][station_name]\n",
    "    except:\n",
    "        latitude = -1\n",
    "    # Only load this file if the station is in the northern hemisphere (a.k.a. having latitude > 0)\n",
    "    if latitude < 0:\n",
    "        continue\n",
    "    \n",
    "    # All the data for one station\n",
    "    df = pd.DataFrame.from_records(load_daily(filename))\n",
    "\n",
    "    # Extract the temperature data\n",
    "    filter_ = np.logical_and(np.logical_and(np.logical_and(np.logical_and(\n",
    "                                        df[\"element\"] != \"TMIN\",\n",
    "                                        df[\"element\"] != \"TMAX\"), \n",
    "                                        df[\"element\"] != \"PRCP\"), \n",
    "                                        df[\"element\"] != \"SNOW\"),\n",
    "                                        df[\"element\"] != \"TAVG\")\n",
    "    \n",
    "    temperatures = df[filter_]\n",
    "\n",
    "    # Delete unnecessary columns\n",
    "    temperatures = temperatures.drop(columns=[\"measurement\", \"quality\", \"source\"])\n",
    "\n",
    "    data_all.append(temperatures)\n",
    "\n",
    "    del filename, station_name, latitude, df, filter_, temperatures\n",
    "print(\"Reading files... DONE\")\n",
    "\n",
    "# Combine all the dataframes\n",
    "data_all = pd.concat(data_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d892ef1-8c58-44e7-8c5d-92fffdcb90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_data = data_all[data_all.value != -9999].dropna()\n",
    "df = nn_data[nn_data.element != 'SNWD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94e82164-573e-4e8c-b54b-21e0091dcc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>element</th>\n",
       "      <th>day</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>ASN00001031</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>DAPR</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>ASN00001031</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>DWPR</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>ASN00001031</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>MDPR</td>\n",
       "      <td>31</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>ASN00001031</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>DAPR</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>ASN00001031</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>DWPR</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95554</th>\n",
       "      <td>USW00094724</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>WSF5</td>\n",
       "      <td>13</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95555</th>\n",
       "      <td>USW00094724</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>WSF5</td>\n",
       "      <td>14</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95556</th>\n",
       "      <td>USW00094724</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>WSF5</td>\n",
       "      <td>15</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95557</th>\n",
       "      <td>USW00094724</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>WSF5</td>\n",
       "      <td>16</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95558</th>\n",
       "      <td>USW00094724</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>WSF5</td>\n",
       "      <td>17</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2474052 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id  year  month element  day  value\n",
       "774    ASN00001031  1998     10    DAPR   31     16\n",
       "805    ASN00001031  1998     10    DWPR   31      5\n",
       "836    ASN00001031  1998     10    MDPR   31    770\n",
       "897    ASN00001031  1998     11    DAPR   30      4\n",
       "928    ASN00001031  1998     11    DWPR   30      4\n",
       "...            ...   ...    ...     ...  ...    ...\n",
       "95554  USW00094724  2021      3    WSF5   13    188\n",
       "95555  USW00094724  2021      3    WSF5   14    183\n",
       "95556  USW00094724  2021      3    WSF5   15    188\n",
       "95557  USW00094724  2021      3    WSF5   16     85\n",
       "95558  USW00094724  2021      3    WSF5   17     81\n",
       "\n",
       "[2474052 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240831d-4133-4343-a6c0-3a5bb301d48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af2f56b6-6c37-4553-91d4-cbc73f9e17d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [01:14<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3434, 1), (1282, 1), (3825, 1), (12, 1), (12, 1), (12, 1), (12, 1), (250, 1), (106, 1), (117, 1), (1052, 1), (776, 1), (1904, 1), (491, 1), (494, 1), (403, 1), (1141, 1), (378, 1), (2086, 1), (911, 1), (1342, 1), (190, 1), (4143, 1), (1007, 1), (184, 1), (256, 1), (241, 1), (107, 1), (107, 1), (52, 1), (52, 1), (350, 1), (109, 1), (11, 1), (100, 1), (101, 1), (43, 1), (43, 1), (61, 1), (61, 1), (9, 1), (9, 1), (10, 1), (10, 1), (145, 1), (13, 1), (185, 1), (71, 1), (132, 1), (131, 1), (132, 1), (131, 1), (41, 1), (2, 1), (44, 1), (35, 1), (1, 1), (1, 1), (36, 1), (37, 1), (7, 1), (6, 1), (6, 1), (33, 1), (47, 1), (17, 1), (6, 1), (36, 1), (4, 1), (6, 1), (28, 1), (28, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_yearly_metrics(metrics):\n",
    "    metrics_data = []\n",
    "    for metric in tqdm.tqdm(metrics):\n",
    "        # Extract the data\n",
    "        data = df.where(df['element'] == metric).dropna()\n",
    "        \n",
    "        # Delete missing data, and unnecessary columns\n",
    "        data = data[data[\"value\"] != -9999]\n",
    "\n",
    "        # For each station and for each year, compute the average metric across that year\n",
    "        result = data.groupby(by=[\"station_id\", \"year\"]).mean()[\"value\"].reset_index()\n",
    "\n",
    "        # Convert year to int type\n",
    "        result[\"year\"] = result[\"year\"].astype(int)\n",
    "        \n",
    "        result = result.set_index([\"station_id\", \"year\"])\n",
    "        result.rename(columns={\"value\": metric}, inplace=True)\n",
    "        \n",
    "        metrics_data.append(result)\n",
    "\n",
    "    return metrics_data\n",
    "\n",
    "# Join the temperature and metric data (on the index a.k.a. the year column)\n",
    "metrics_list = df['element'].unique()\n",
    "\n",
    "# data = pd.concat(data, axis=1, join=\"inner\", ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e5b08cd8-7663-489f-876d-19f073bc6d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [01:18<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11486, 1), (3434, 1), (1282, 1), (3825, 1), (12, 1), (12, 1), (12, 1), (12, 1), (250, 1), (106, 1), (117, 1), (1052, 1), (776, 1), (1904, 1), (491, 1), (494, 1), (403, 1), (1141, 1), (378, 1), (2086, 1), (911, 1), (1342, 1), (190, 1), (4143, 1), (1007, 1), (184, 1), (256, 1), (241, 1), (107, 1), (107, 1), (52, 1), (52, 1), (350, 1), (109, 1), (11, 1), (100, 1), (101, 1), (43, 1), (43, 1), (61, 1), (61, 1), (9, 1), (9, 1), (10, 1), (10, 1), (145, 1), (13, 1), (185, 1), (71, 1), (132, 1), (131, 1), (132, 1), (131, 1), (41, 1), (2, 1), (44, 1), (35, 1), (1, 1), (1, 1), (36, 1), (37, 1), (7, 1), (6, 1), (6, 1), (33, 1), (47, 1), (17, 1), (6, 1), (36, 1), (4, 1), (6, 1), (28, 1), (28, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = [temps] + compute_yearly_metrics(metrics_list)\n",
    "print([x.shape for x in data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a218e3e0-3b69-46ed-8986-5044420785fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_data = [x if x.shape[0] > 400 else _ for x in data]\n",
    "data_df = pd.concat(data, axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "50688fb8-cf6c-493e-a391-0733567a9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_df_list = []\n",
    "for col in data_df.columns:\n",
    "    if col == 'temp':\n",
    "        continue\n",
    "    factor_df_list.append(data_df[['temp', col]])\n",
    "        \n",
    "factor_df_list_adj = []\n",
    "for df_ in factor_df_list:\n",
    "    tr_df = df_.dropna().reset_index(level=\"year\")\n",
    "    year_column = tr_df[\"year\"]\n",
    "    all_years = year_column.unique()\n",
    "    all_years.sort()\n",
    "    if len(all_years) <= 2:\n",
    "        continue\n",
    "    all_adj_years = np.lib.stride_tricks.sliding_window_view(all_years, 2)\n",
    "    factor_df_list_adj.append((tr_df, all_adj_years)) if df_.dropna().shape[0] > 100 else _\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97330a29-3163-4519-9bbe-e1be02935d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_df_list_adj[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "68225369-eabe-4b92-b8aa-deb21b9f8f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:00<00:00, 139.66it/s]\n",
      "100%|██████████| 105/105 [00:00<00:00, 163.43it/s]\n",
      "100%|██████████| 73/73 [00:00<00:00, 192.88it/s]\n",
      "100%|██████████| 52/52 [00:00<00:00, 180.63it/s]\n",
      "100%|██████████| 52/52 [00:00<00:00, 99.62it/s] \n",
      "100%|██████████| 57/57 [00:00<00:00, 143.38it/s]\n",
      "100%|██████████| 125/125 [00:00<00:00, 143.45it/s]\n",
      "100%|██████████| 118/118 [00:00<00:00, 169.05it/s]\n",
      "100%|██████████| 113/113 [00:00<00:00, 169.78it/s]\n",
      "100%|██████████| 110/110 [00:00<00:00, 179.32it/s]\n",
      "100%|██████████| 126/126 [00:00<00:00, 160.83it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 178.85it/s]\n",
      "100%|██████████| 128/128 [00:01<00:00, 112.64it/s]\n",
      "100%|██████████| 96/96 [00:00<00:00, 155.29it/s]\n",
      "100%|██████████| 126/126 [00:00<00:00, 161.05it/s]\n",
      "100%|██████████| 69/69 [00:00<00:00, 192.32it/s]\n",
      "100%|██████████| 124/124 [00:01<00:00, 121.33it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 154.31it/s]\n",
      "100%|██████████| 73/73 [00:00<00:00, 192.62it/s]\n",
      "100%|██████████| 82/82 [00:00<00:00, 130.49it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 192.68it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 157.71it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 149.01it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 187.11it/s]\n",
      "100%|██████████| 37/37 [00:00<00:00, 173.40it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 184.94it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 154.13it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 158.63it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 143.48it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 141.91it/s]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "outputs = []\n",
    "for df_adj in factor_df_list_adj:\n",
    "    df_, all_adj_years = df_adj\n",
    "    num_sig_factor = 0\n",
    "    \n",
    "    for (year1, year2) in tqdm.tqdm(all_adj_years):\n",
    "        # Get station data for both years\n",
    "        data_year1 = df_[df_['year'] == year1]\n",
    "        data_year2 = df_[df_['year'] == year2]\n",
    "        \n",
    "        # Get specific columns\n",
    "        temp_year1 = data_year1[\"temp\"]\n",
    "        temp_year2 = data_year2[\"temp\"]\n",
    "        factor_year1 = data_year1[data_year1.columns[-1]]\n",
    "        factor_year2 = data_year2[data_year2.columns[-1]]\n",
    "\n",
    "        # Inner join on station id to find observations common between both years, and\n",
    "        # then compute the differences\n",
    "        temp_year_diff = pd.DataFrame(temp_year1).join(temp_year2, how=\"inner\",\n",
    "                                                         lsuffix=\"_{}\".format(year1),\n",
    "                                                         rsuffix=\"_{}\".format(year2)).diff(axis=1).iloc[:, 1]\n",
    "        factor_year_diff = pd.DataFrame(factor_year1).join(factor_year2, how=\"inner\",\n",
    "                                                         lsuffix=\"_{}\".format(year1),\n",
    "                                                         rsuffix=\"_{}\".format(year2)).diff(axis=1).iloc[:, 1]    \n",
    "        # Only looking at cases where there are at least 5 values. \n",
    "        # The sign test is able to handle a small number of values \n",
    "        # but we want to cap at 5 values minimum.\n",
    "        if factor_year_diff.shape[0] < 5 or temp_year_diff.shape[0] < 5:\n",
    "            continue\n",
    "        # Count the number of differences that are positive\n",
    "        #\n",
    "        # These three values will serve as our test statistics for a sign test on temperature,\n",
    "        # a sign test on precipitation, and a sign test on snowfall, respectively\n",
    "        test_stat_temp = np.count_nonzero(temp_year_diff > 0)\n",
    "        test_stat_factor = np.count_nonzero(factor_year_diff > 0)\n",
    "\n",
    "        # Convert each test statistic into a p-value using the binomial test. In this case, each\n",
    "        # test statistic is defined as the number of successes (a.k.a. the number of stations\n",
    "        # for which temperature increased, precipitation increased, and snowfall increased,\n",
    "        # respectively) out of all stations\n",
    "        p_value_temp = stats.binomtest(k=test_stat_temp, n=temp_year_diff.size, alternative='two-sided').pvalue\n",
    "        p_value_factor = stats.binomtest(k=test_stat_factor, n=factor_year_diff.size, alternative='two-sided').pvalue\n",
    "\n",
    "        # If the p-values for temperature and precipitation are BOTH significant, then it means\n",
    "        # that between year1 and year2, temperature and precipitation BOTH had a statistically\n",
    "        # significant increase\n",
    "        if p_value_temp < alpha and p_value_factor < alpha:\n",
    "            num_sig_factor += 1\n",
    "    outputs.append((df_.columns[-1], num_sig_factor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "52365d60-c38c-48b9-b601-c30b4d4674fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(factor_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "774f22be-5e2e-4fad-ad6e-ef4cbcd10ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>DWPR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ASN00015089</th>\n",
       "      <th>1976</th>\n",
       "      <td>25.184211</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>25.660606</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>30.145588</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ASN00018120</th>\n",
       "      <th>1983</th>\n",
       "      <td>16.493726</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>18.124344</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>17.732787</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>18.046027</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>17.490000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ASN00030024</th>\n",
       "      <th>1990</th>\n",
       "      <td>24.426374</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>24.401389</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ASN00040852</th>\n",
       "      <th>1993</th>\n",
       "      <td>18.451567</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>19.763793</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>18.460792</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>18.382877</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>29.583871</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ASN00086097</th>\n",
       "      <th>1965</th>\n",
       "      <td>14.190500</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>14.193750</td>\n",
       "      <td>2.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>14.299705</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>14.230249</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>14.169452</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ASN00091007</th>\n",
       "      <th>1971</th>\n",
       "      <td>13.268508</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>13.195219</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>12.956849</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>12.962842</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>12.652358</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ASN00091250</th>\n",
       "      <th>1986</th>\n",
       "      <td>14.002381</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>10.918293</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>12.287273</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ASN00096003</th>\n",
       "      <th>1976</th>\n",
       "      <td>7.862295</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>7.668219</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       temp      DWPR\n",
       "station_id  year                     \n",
       "ASN00015089 1976  25.184211  3.000000\n",
       "            1978  25.660606  2.000000\n",
       "            1980  30.145588  2.666667\n",
       "ASN00018120 1983  16.493726  2.000000\n",
       "            1988  18.124344  2.333333\n",
       "            2004  17.732787  3.000000\n",
       "            2005  18.046027  2.000000\n",
       "            2006  17.490000  2.000000\n",
       "ASN00030024 1990  24.426374  2.000000\n",
       "            1999  24.401389  2.000000\n",
       "ASN00040852 1993  18.451567  2.750000\n",
       "            1994  19.763793  2.250000\n",
       "            1996  18.460792  2.000000\n",
       "            1997  18.382877  2.000000\n",
       "            1999  29.583871  2.000000\n",
       "ASN00086097 1965  14.190500  2.571429\n",
       "            1966  14.193750  2.409091\n",
       "            1967  14.299705  2.500000\n",
       "            1973  14.230249  2.000000\n",
       "            1976  14.169452  2.000000\n",
       "ASN00091007 1971  13.268508  1.666667\n",
       "            1972  13.195219  1.000000\n",
       "            1975  12.956849  2.000000\n",
       "            1976  12.962842  2.000000\n",
       "            1978  12.652358  2.000000\n",
       "ASN00091250 1986  14.002381  1.000000\n",
       "            1987  10.918293  1.000000\n",
       "            1988  12.287273  1.000000\n",
       "ASN00096003 1976   7.862295  2.000000\n",
       "            1985   7.668219  2.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dapr.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e7d84-c135-4845-9dea-dc1dd3610a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
